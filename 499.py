# -*- coding: utf-8 -*-
"""499.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SVuzBYFyYifdbVjVQvd3_2QidG6FHsYH
"""

from google.colab import drive
drive.mount("/content/drive", force_remount=True)

def mergeImages():
  import matplotlib.pyplot as plt
  import numpy as np
  edge_dir = "/content/drive/My Drive/M499/3"
  original_dir = "/content/drive/My Drive/M499/tranch3/tranch3"
  import os
  for ori in sorted(os.listdir(original_dir)):
    ori_img = plt.imread(os.path.join(original_dir,ori))
    file_name = ori.rsplit(".")[0]
    edge_img = None
    for edge in sorted(os.listdir(edge_dir)):
      edge_file_name = edge.rsplit(".")[0]
      if (edge_file_name == file_name):
        edge_img = plt.imread(os.path.join(edge_dir, edge))
        break
    if edge_img is not None:
      X = np.zeros(edge_img.shape + (4,))
      X[...,:3] = ori_img
      X[...,-1] = edge_img
      try:
        plt.imsave("/content/drive/My Drive/M499/merge3/" + file_name + ".png", X)
      except ValueError as e: # 0-255 as jpg, but should be 0-1
        X = np.zeros(edge_img.shape + (4,))
        X[...,:3] = ori_img / 255
        X[...,-1] = edge_img / 255
        plt.imsave("/content/drive/My Drive/M499/merge3/" + file_name + ".png", X)
    else:
      print(ori, "not found")

"""# import"""

# !unrar e '/content/drive/My Drive/M499/edge/tranch2_edge.rar' '/content/drive/My Drive/M499/edge'

# !mkdir /content/drive/My\ Drive/M499/data

# !unzip /content/drive/My\ Drive/M499/persons-posture-tranch1.zip -d /content/drive/My\ Drive/M499/data

from zipfile import ZipFile
import matplotlib.pyplot as plt
import tensorflow as tf
import albumentations as A
from tensorflow.keras import datasets, layers, models
import numpy as np
!pip install git+https://github.com/mjkvaak/ImageDataAugmentor
from ImageDataAugmentor.image_data_augmentor import *
import seaborn as sns
import pandas as pd
# !pip install decord
# import decord
import torch
from torchvision import transforms
# !pip install facenet-pytorch
# from facenet_pytorch import MTCNN

"""# team2net"""

merge_dir = "/content/drive/My Drive/M499/merge3/"
tranch = 3
labels_path = '/content/drive/My Drive/M499/tranch'+str(tranch)+'_labels.csv'
pictures_path = '/content/drive/My Drive/M499/persons-posture-tranch'+str(tranch)+'.zip'

labels = pd.read_csv(labels_path)
zip_file = ZipFile(pictures_path)

file_list = [obj.filename for obj in zip_file.infolist()]
file_list_simple = [name.split('/')[-1] for name in file_list]

df = labels
len(df)

df["final_url"] = df["final_url"].str.replace("PNG", 'png')
df["final_url"] = df["final_url"].str.replace("JPG", 'png')

df = df.dropna()
df.index = range(len(df))
df["primary_posture"].value_counts()

from sklearn.model_selection import train_test_split
train, test = train_test_split(df, test_size=0.33, random_state=42)
train = train.query("primary_posture != 'Unknown'")
test = test.query("primary_posture != 'Unknown'")
len(train), len(test)

train["primary_posture"] .value_counts() / len(train)

test["primary_posture"] .value_counts()  / len(test)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                            shear_range=0.1,
                            zoom_range=0.1,
                            width_shift_range=0.1,
                            height_shift_range=0.1,
                            brightness_range=[0.9,1.1],
                            horizontal_flip=True,
                            validation_split=0.2,
                            # preprocessing_function=custom_preprocess
)

val_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                             validation_split=0.2,
                            #  preprocessing_function= mobilenet_v2.preprocess_input
)

test_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                            #  preprocessing_function= mobilenet_v2.preprocess_input
)

train_gen = train_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/merge3/",
                            x_col = "final_url",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            color_mode="rgba",
                            batch_size = 32,
                            seed=42,
                            subset = "training",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

val_gen = val_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/merge3/",
                            x_col = "final_url",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            color_mode="rgba",
                            batch_size = 32,
                            seed=42,
                            subset = "validation",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)


test_gen = test_datagen.flow_from_dataframe(test,
                            directory = "/content/drive/My Drive/M499/merge3/",
                            x_col = "final_url",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            color_mode="rgba",
                            batch_size = 32,
                            seed=42,
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

import tensorflow as tf
import numpy as np


class team2netBlock(tf.keras.layers.Layer):
    def __init__(self, filter_num, stride):
        super().__init__()

        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,
                                            kernel_size=(3, 3),
                                            strides=stride,
                                            padding='same', name='block_conv1', input_shape=(56, 56, 3))
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,
                                            kernel_size=(3, 3),
                                            strides=1,
                                            padding='same', name='block_conv2', input_shape=(56, 56, filter_num))
        self.bn2 = tf.keras.layers.BatchNormalization()

        if stride != 1:
            self.downsample = tf.keras.Sequential()
            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,
                                                       kernel_size=(1, 1),
                                                       strides=stride))
            self.downsample.add(tf.keras.layers.BatchNormalization())
        else:
            self.downsample = lambda x: x

    # @tf.function
    def call(self, inputs: list, training=None):
        x, residual = inputs[0], inputs[1]
        residual = self.downsample(residual)
        x = self.conv1(x)
        x = self.bn1(x, training=training)
        x = tf.nn.relu(x)
        x = self.conv2(x)
        x = self.bn2(x, training=training)
        x = tf.nn.relu(x)
        output = tf.nn.relu(tf.keras.layers.add([residual, x]))
        return output, residual


class team2net(tf.keras.Model):
    def __init__(self, layer_params):
        super().__init__()
        self.layer_params = layer_params
        self.conv1 = tf.keras.layers.Conv2D(filters=64,
                                            kernel_size=(7, 7),
                                            strides=2,
                                            padding="same")
        self.convEdge = tf.keras.layers.Conv2D(filters=1,
                                               kernel_size=(7, 7),
                                               strides=2,
                                               padding="same", name='convEdge')
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),
                                               strides=2,
                                               padding="same")

        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()
        self.fc = tf.keras.layers.Dense(3, activation=tf.keras.activations.softmax)

    def resblock(self, inputs, residual, filter_num, blocks, stride):
        inputs, residual = team2netBlock(filter_num, stride=stride)([inputs, residual])
        for i in range(1, blocks):
            inputs, residual = team2netBlock(filter_num, stride=1)([inputs, residual])
        return inputs, residual


    def call(self, inputs, training=None):
        x = tf.keras.layers.Lambda(lambda x: x[..., :3])(inputs)
        residual = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x[..., -1], -1))(inputs)
        x = self.conv1(x)
        x = self.bn1(x, training=training)
        x = tf.nn.relu(x)
        x = self.pool1(x)
        residual = self.convEdge(residual)
        residual = self.pool1(residual)

        # start skip
        x, residual = self.resblock(x, residual, filter_num=64,
                                    blocks = self.layer_params[0], stride =1)

        x, residual = self.resblock(x, residual, filter_num=128,
                                    blocks = self.layer_params[1], stride =2)

        x, residual = self.resblock(x, residual, filter_num=256,
                                    blocks = self.layer_params[2], stride =2)

        x, residual = self.resblock(x, residual, filter_num=512,
                                    blocks = self.layer_params[3], stride =2)

        x = self.avgpool(x)
        output = self.fc(x)
        return output

    def model(self):
        x = tf.keras.Input(shape=(224, 224, 4))
        return tf.keras.Model(inputs=[x], outputs=self.call(x))


team2net34 = team2net([3, 4, 6, 3]).model()

from tensorflow.keras import optimizers, losses
team2net34.build(input_shape=(None, 224, 224, 4))
team2net34.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=1e-3),
    metrics=['accuracy'])
team2net34.summary()

def train_model(model):
  from datetime import datetime
  import json
  
  save_dir = "/content/drive/My Drive/model/team2net"
 
  # Reduce learning rate when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.01,
                                                  patience = 3,
                                                  factor = 0.25,
                                                  verbose = 1,
                                                  cooldown = 0,
                                                  min_lr = 0.00000001)
 
  # Stop the training process when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.005,
                                                  patience = 13,
                                                  verbose = 1,
                                                  restore_best_weights = True)
  

  txt_log = open(save_dir+".log", mode='wt', buffering=1)
  
  log_callback = tf.keras.callbacks.LambdaCallback(
    on_epoch_end = lambda epoch, logs: txt_log.write(
      json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\n'),
    on_train_end = lambda logs: txt_log.close()
  )


  his = model.fit(train_gen, 
      steps_per_epoch=171,
      epochs=60,
      callbacks=[
                 tf.keras.callbacks.ModelCheckpoint(filepath=save_dir + '.{epoch:02d}-{val_accuracy:.2f}.h5'),
                 early_stopper, reduce_lr,
                 log_callback,
                 ],
      verbose = 1,
      # class_weight = class_weights,
      validation_data = val_gen,
      validation_steps = 42,
      shuffle = True,
  )
  plt.plot(his.history["accuracy"], label = "training")
  plt.plot(his.history["val_accuracy"], label = "validating")
  plt.legend()
  plt.savefig(save_dir + "plot.jpg")
 
  cur = datetime.now()
  save_dir += str(cur.day) + "-" + str(cur.hour)
 
  model.save(save_dir)
train_model(team2net34)

"""# tranch 1"""

labels_path = '/content/drive/My Drive/M499/tranch2_labels.csv'
labels = pd.read_csv(labels_path)

labels["final_url"][0]

img = cv2.imread("/content/drive/My Drive/M499/edge/" + labels["final_url"][0])
plt.imshow(img)

tranch = 1
labels_path = '/content/drive/My Drive/M499/tranch'+str(tranch)+'_labels.csv'
pictures_path = '/content/drive/My Drive/M499/persons-posture-tranch'+str(tranch)+'.zip'

labels = pd.read_csv(labels_path)
zip_file = ZipFile(pictures_path)

file_list = [obj.filename for obj in zip_file.infolist()]
file_list_simple = [name.split('/')[-1] for name in file_list]

pd.read_csv('/content/drive/My Drive/M499/tranch1_labels.csv')

pd.read_csv('/content/drive/My Drive/M499/tranch3_labels.csv')

names = pd.DataFrame({'file_path': file_list, 'file_name': file_list_simple})
names.head()

def openImg(idx):
  img = zip_file.open(df.iloc[idx].file_path)
  return plt.imread(img)

df = pd.merge(names, labels, on = 'file_name')
print(len(names), len(labels), len(df))

df.info()

# for now discard null
df.isnull().sum()

df = df.dropna()
df.index = range(len(df))

# from sklearn.preprocessing import LabelEncoder

# how_many = df["how_many"]
# print(how_many.unique())
# df["how_many"] = LabelEncoder().fit_transform(df["how_many"])
# df.head()

df["primary_posture"].value_counts()

from sklearn.model_selection import train_test_split
train, test = train_test_split(df, test_size=0.33, random_state=42)

len(train), len(test)





"""# Keras"""

train.head()

sns.countplot("primary_posture", hue = "primary_occluded", data = train)

sns.catplot(x="primary_posture", hue="how_many", col="primary_occluded",
                data=train, kind="count",
                height=10, aspect=0.7)

def show_some_from_df(df):
  plt.figure(1, figsize=(15,12))

  for idx, row in enumerate(df.index,1):
    if idx == 10: break;
    plt.subplot(3,3,idx)
    plt.imshow(openImg(row))
    plt.title(f'img {idx}: {df.iloc[idx].primary_posture}')
  plt.tight_layout()

show_some_from_df(
    train.query("primary_occluded == 'Unknown / Watermark'")
)

show_some_from_df(
    train.query("how_many == 'None'")
)

show_some_from_df(
    train.query("staff_patient_other == 'Other'")
)

show_some_from_df(
    train.query("primary_posture == 'Unknown'")
)

# discard unknown
# we can train the model first and then predict unknown
train = train.query("primary_posture != 'Unknown'")

train["primary_posture"] .value_counts() / len(train)

test = test.query("primary_posture != 'Unknown'")

test["primary_posture"] .value_counts()  / len(test)

"""# MobileNet"""

!nvidia-smi

def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):
    def eraser(input_img):
        if input_img.ndim == 3:
            img_h, img_w, img_c = input_img.shape
        elif input_img.ndim == 2:
            img_h, img_w = input_img.shape

        p_1 = np.random.rand()

        if p_1 > p:
            return input_img

        while True:
            s = np.random.uniform(s_l, s_h) * img_h * img_w
            r = np.random.uniform(r_1, r_2)
            w = int(np.sqrt(s / r))
            h = int(np.sqrt(s * r))
            left = np.random.randint(0, img_w)
            top = np.random.randint(0, img_h)

            if left + w <= img_w and top + h <= img_h:
                break

        if pixel_level:
            if input_img.ndim == 3:
                c = np.random.uniform(v_l, v_h, (h, w, img_c))
            if input_img.ndim == 2:
                c = np.random.uniform(v_l, v_h, (h, w))
        else:
            c = np.random.uniform(v_l, v_h)

        input_img[top:top + h, left:left + w] = c

        return input_img

    return eraser

def cropExample(idx):
  plt.figure(figsize = (120,100))
  img = openImg(idx).copy()
  plt.subplot(1,2,1)
  plt.imshow(img.astype(np.uint8))

  plt.subplot(1,2,2)
  eraser = get_random_eraser()
  img = eraser(img)
  plt.imshow(img.astype(np.uint8))
  
  plt.tight_layout()

cropExample(0)

from imblearn.over_sampling import SMOTE

sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(flatten_batch, label_batch)

y_resampled

np.unique(y_resampled, return_counts = True)

np.unique(label_batch, return_counts = True)

label_batch

newimg = X_resampled[-1].reshape((224,224,3))

plt.imshow(newimg)
plt.axis(False)
plt.figure(figsize=(10,10))

plt.imshow(X_resampled[31].reshape((224,224,3)))

plt.imshow(image_batch[31])

flatten_batch = image_batch.reshape(32, -1)
flatten_batch.shape



label_batch

img = openImg(0)
plt.figure(figsize = (120,100))
plt.subplot(1,2,1)
plt.imshow(img)
plt.subplot(1,2,2)
# plt.imshow(A.GridDistortion()(image = img)['image'])
plt.imshow(A.ElasticTransform(
                  alpha=img.shape[0],
                  sigma=img.shape[0] * 0.05,
                  alpha_affine=img.shape[0] * 0.03)(image = img)['image'])

plt.tight_layout()

from tensorflow.keras.applications import MobileNetV2, mobilenet_v2

custom_preprocess = lambda img: mobilenet_v2.preprocess_input(get_random_eraser()(img))

AUGMENTATIONS = A.Compose([
            A.Rotate(limit=40),
            A.OneOf([
                     A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),
                     A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)
            ]),
            A.OneOf([
                     A.ElasticTransform(alpha=224, sigma=224 * 0.05, alpha_affine=224 * 0.03),
                     A.GridDistortion(),
                     A.OpticalDistortion(distort_limit=2, shift_limit=0.5),
            ], p=0.3),
            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),
            A.RandomContrast(limit=0.2, p=0.5),
            A.HorizontalFlip(),
            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10),
    ])

train_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                            augment = AUGMENTATIONS,
                            preprocess_input = custom_preprocess,
                            validation_split=0.2,
)

val_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                             validation_split=0.2,
                             preprocess_input= mobilenet_v2.preprocess_input
)

test_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                             preprocess_input= mobilenet_v2.preprocess_input
)

train_gen = train_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "training",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

val_gen = val_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "validation",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)


test_gen = test_datagen.flow_from_dataframe(test,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

train_gen.show_batch()

def view_image(gen):
    image, label = next(iter(gen)) # extract 1 batch from the dataset

    fig = plt.figure(figsize=(22, 22))
    for i in range(20):
        ax = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])
        ax.imshow(image[i])
        ax.set_title(f"Label: {label[i]}")
view_image(train_gen)

from tensorflow.keras.layers import (GlobalAveragePooling2D, 
  Dropout, Dense, BatchNormalization)
from tensorflow.keras import optimizers, losses
from tensorflow.keras.applications import MobileNetV2, mobilenet_v2


base_model=MobileNetV2(weights='imagenet',include_top=False,
                       input_shape = (224, 224, 3))
base_model.trainable = True
inputs = tf.keras.Input(shape=(224, 224, 3), name = "image_input")
x = base_model(inputs, training=True, )
# x=keras.base_model.output
x=GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
x=Dense(1024,activation='relu')(x)
x=Dense(1024,activation='relu')(x)
x=Dense(512,activation='relu')(x)
x=Dense(128,activation='relu')(x)
preds=Dense(3,activation='softmax')(x)
 
model= tf.keras.Model(inputs=inputs,outputs=[preds], name = "our model")
model.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=1e-3),
    metrics=['accuracy'])

for l in model.layers:
  if l.name.startswith("mobile"):
    l._name = "mobilenetv2"
  # if l.name.startswith("global_average"):
    # l._name = "gloabl_average"

model.summary()

tf.keras.utils.plot_model(model)

from sklearn.utils import class_weight
y_train = train["primary_posture"].map(train_gen.class_indices).values
class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight('balanced',
                                                 np.unique(y_train),
                                                 y_train)))

def train_model(model):
  from datetime import datetime
 
  
  save_dir = "/content/drive/My Drive/mobile3rd"
 
  # Reduce learning rate when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.01,
                                                  patience = 3,
                                                  factor = 0.25,
                                                  verbose = 1,
                                                  cooldown = 0,
                                                  min_lr = 0.00000001)
 
  # Stop the training process when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.005,
                                                  patience = 10,
                                                  verbose = 1,
                                                  restore_best_weights = True)
  his = model.fit(train_gen, 
      steps_per_epoch=242,
      epochs=60,
      callbacks=[
                 tf.keras.callbacks.ModelCheckpoint(filepath=save_dir + '.{epoch:02d}-{val_accuracy:.2f}.h5'),
                 early_stopper, reduce_lr],
      verbose = 1,
      # class_weight = class_weights,
      validation_data = val_gen,
      validation_steps = 61,
      shuffle = True,
  )
  plt.plot(his.history["accuracy"], label = "training")
  plt.plot(his.history["val_accuracy"], label = "validating")
  plt.legend()
 
  cur = datetime.now()
  save_dir += str(cur.day) + "-" + str(cur.hour) + ".h5"
 
  model.save(save_dir)
train_model(model)

model.load_weights("/content/drive/My Drive/mobile3rd.19-0.89.h5")

model.evaluate(test_gen)

def predict_acc(model, test_gen):
  from sklearn.metrics import accuracy_score
  y_pred = model.predict(test_gen, verbose = 1)
  pred_cls = np.argmax(y_pred, axis=1)
 
  true_cls = test["primary_posture"].map(test_gen.class_indices).values
 
  return accuracy_score(pred_cls, true_cls), y_pred
 
acc, y_pred = predict_acc(model, test_gen)

y_pred.shape

y_pred

np.unique(np.argmax(y_pred, axis=1), return_counts=True)

pred_cls = np.argmax(y_pred, axis=1)

pred_cls

true_cls = test["primary_posture"].map(test_gen.class_indices).values

true_cls

np.sum(pred_cls == true_cls) / len(pred_cls)

np.sum(pred_cls == true_cls)

len(true_cls)

test_gen.reset()

y_pred = model.predict_generator(test_gen, verbose = 1)

pred_cls = np.argmax(y_pred, axis=1)

from sklearn.metrics import accuracy_score

accuracy_score(pred_cls, true_cls)

test_gen = test_datagen.flow_from_dataframe(test,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            shuffle=False,
                            target_size=(224, 224),
                            validate_filenames = True,
)

test_gen.reset()

y_pred = model.predict(test_gen, verbose = 1)

pred_cls = np.argmax(y_pred, axis=1)

accuracy_score(pred_cls, true_cls)

from sklearn.metrics import classification_report
print(classification_report(y_true=test_gen.classes, y_pred=pred_cls, target_names=test_gen.class_indices))

cm

df.index = df.index.map(lambda x: "true: " + str(x))

df

plt.figure(figsize=(10, 10))
sns.heatmap(df, annot=True, fmt='d')

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(test_gen.classes, pred_cls)
df = pd.DataFrame(cm, columns=test_gen.class_indices)
plt.figure(figsize=(10, 10))
sns.heatmap(df, annot=True)



"""## Already run"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2, mobilenet_v2

custom_preprocess = lambda img: mobilenet_v2.preprocess_input(get_random_eraser()(img))


train_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                            shear_range=0.1,
                            zoom_range=0.1,
                            width_shift_range=0.1,
                            height_shift_range=0.1,
                            brightness_range=[0.9,1.1],
                            horizontal_flip=True,
                            validation_split=0.2,
                            preprocessing_function=custom_preprocess
)

val_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                             validation_split=0.2,
                             preprocessing_function= mobilenet_v2.preprocess_input
)

train_gen = train_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "training",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

val_gen = val_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "validation",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

test_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                             preprocessing_function= mobilenet_v2.preprocess_input
)

test_gen = test_datagen.flow_from_dataframe(test,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

def train_model(model):
  from datetime import datetime
 
  
  save_dir = "/content/drive/My Drive/mobile 2nd"
 
  # Reduce learning rate when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.01,
                                                  patience = 3,
                                                  factor = 0.25,
                                                  verbose = 1,
                                                  cooldown = 0,
                                                  min_lr = 0.00000001)
 
  # Stop the training process when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.005,
                                                  patience = 10,
                                                  verbose = 1,
                                                  restore_best_weights = True)
  his = model.fit(train_gen, 
      steps_per_epoch=242,
      epochs=60,
      callbacks=[
                 tf.keras.callbacks.ModelCheckpoint(filepath=save_dir + '.{epoch:02d}-{val_loss:.2f}.h5'),
                 early_stopper, reduce_lr],
      verbose = 1,
      class_weight = class_weights,
      validation_data = val_gen,
      validation_steps = 61,
      shuffle = True,
  )
  plt.plot(his.history["accuracy"], label = "training")
  plt.plot(his.history["val_accuracy"], label = "validating")
  plt.legend()
 
  cur = datetime.now()
  save_dir += str(cur.day) + "-" + str(cur.hour) + ".h5"
 
  model.save(save_dir)
train_model(model)

# without class_weight
def train_model(model):
  from datetime import datetime

  
  save_dir = "/content/drive/My Drive/mobile"

  # Reduce learning rate when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.01,
                                                  patience = 3,
                                                  factor = 0.25,
                                                  verbose = 1,
                                                  cooldown = 0,
                                                  min_lr = 0.00000001)

  # Stop the training process when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.005,
                                                  patience = 10,
                                                  verbose = 1,
                                                  restore_best_weights = True)
  his = model.fit(train_gen, 
      steps_per_epoch=242,
      epochs=60,
      callbacks=[
                 tf.keras.callbacks.ModelCheckpoint(filepath=save_dir + '.{epoch:02d}-{val_loss:.2f}.h5'),
                 early_stopper, reduce_lr],
      verbose = 1,
      # class_weight = class_weights,
      validation_data = val_gen,
      validation_steps = 61,
      shuffle = True,
  )
  plt.plot(his.history["accuracy"], label = "training")
  plt.plot(his.history["val_accuracy"], label = "validating")
  plt.legend()

  cur = datetime.now()
  save_dir += str(cur.day) + "-" + str(cur.hour) + ".h5"

  model.save(save_dir)
train_model(model)

model.evaluate(val_gen)

model.evaluate(test_gen)

def predict_acc(model, test_gen):
  from sklearn.metrics import accuracy_score
  y_pred = model.predict(test_gen, verbose = 1)
  pred_cls = np.argmax(y_pred, axis=1)
 
  true_cls = test["primary_posture"].map(test_gen.class_indices).values
 
  return accuracy_score(pred_cls, true_cls)
 
predict_acc(model, test_gen)

model.load_weights("/content/drive/My Drive/mobile.36-0.38.h5")

model.evaluate(test_gen)

def predict_acc(model, test_gen):
  from sklearn.metrics import accuracy_score
  y_pred = model.predict(test_gen, verbose = 1)
  pred_cls = np.argmax(y_pred, axis=1)
 
  true_cls = test["primary_posture"].map(test_gen.class_indices).values
 
  return accuracy_score(pred_cls, true_cls), y_pred
 
acc, y_pred = predict_acc(model, test_gen)



model.predict(test_gen, verbose = 1)

y_pred = Out[54];
y_pred.shape

pred_cls = np.argmax(y_pred, axis=1)
true_cls = test["primary_posture"]

true_cls = true_cls.map(test_gen.class_indices).values

from sklearn.metrics import accuracy_score
accuracy_score(pred_cls, true_cls)

test_gen.class_indices

from tensorflow.keras.layers import (GlobalAveragePooling2D, 
  Dropout, Dense, BatchNormalization)
from tensorflow.keras import optimizers, losses
 
 
base_model=MobileNetV2(weights='imagenet',include_top=False,
                       input_shape = (224, 224, 3))
base_model.trainable = True
x=base_model.output
x=GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
x=Dense(512,activation='relu')(x)
x=Dense(256,activation='relu')(x)
x=Dense(128,activation='relu')(x)
preds=Dense(3,activation='softmax')(x)
 
model= tf.keras.Model(inputs=[base_model.input],outputs=[preds])
model.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=1e-3),
    metrics=['accuracy'])

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2, mobilenet_v2

custom_preprocess = lambda img: mobilenet_v2.preprocess_input(
    elastic_transform(
        get_random_eraser()(img),
        img.shape[1] * 2, img.shape[1] * 0.08, img.shape[1] * 0.08
        )
)


train_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                            shear_range=0.1,
                            zoom_range=0.1,
                            width_shift_range=0.1,
                            height_shift_range=0.1,
                            brightness_range=[0.9,1.1],
                            horizontal_flip=True,
                            validation_split=0.2,
                            preprocessing_function=custom_preprocess
)

val_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                             validation_split=0.2,
                             preprocessing_function= mobilenet_v2.preprocess_input
)

train_gen = train_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "training",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

val_gen = val_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "validation",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)


test_datagen = ImageDataGenerator(data_format="channels_last",
                            #  rescale = 1./255,
                             preprocessing_function= mobilenet_v2.preprocess_input
)

test_gen = test_datagen.flow_from_dataframe(test,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

# less dense layer more dropout
# doesn't work
def train_model(model):
  from datetime import datetime

  
  save_dir = "/content/drive/My Drive/mobile3rd"

  # Reduce learning rate when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.01,
                                                  patience = 3,
                                                  factor = 0.25,
                                                  verbose = 1,
                                                  cooldown = 0,
                                                  min_lr = 0.00000001)

  # Stop the training process when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.005,
                                                  patience = 10,
                                                  verbose = 1,
                                                  restore_best_weights = True)
  his = model.fit(train_gen, 
      steps_per_epoch=242,
      epochs=60,
      callbacks=[
                 tf.keras.callbacks.ModelCheckpoint(filepath=save_dir + '.{epoch:02d}-{val_loss:.2f}.h5'),
                 early_stopper, reduce_lr],
      verbose = 1,
      # class_weight = class_weights,
      validation_data = val_gen,
      validation_steps = 61,
      shuffle = True,
  )
  plt.plot(his.history["accuracy"], label = "training")
  plt.plot(his.history["val_accuracy"], label = "validating")
  plt.legend()

  cur = datetime.now()
  save_dir += str(cur.day) + "-" + str(cur.hour) + ".h5"

  model.save(save_dir)
train_model(model)

"""## freeze"""

from tensorflow.keras.layers import (GlobalAveragePooling2D, 
  Dropout, Dense, BatchNormalization)
from tensorflow.keras import optimizers, losses


base_model=MobileNetV2(weights='imagenet',include_top=False,
                       input_shape = (224, 224, 3))
base_model.trainable = False
x=base_model.output
x=GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
x=Dense(1024,activation='relu')(x)
x=Dense(1024,activation='relu')(x)
x=Dense(512,activation='relu')(x)
x=Dense(128,activation='relu')(x)
preds=Dense(3,activation='softmax')(x)

model= tf.keras.Model(inputs=base_model.input,outputs=preds)
model.summary()

model.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=1e-3),
    metrics=['accuracy'])

his = model.fit(train_gen, 
      steps_per_epoch=240,
      epochs=30,
      verbose = 1,
      validation_data = val_gen,
      validation_steps = 10,
      shuffle = True,
)

plt.plot(his.history["accuracy"], label = "training")
plt.plot(his.history["val_accuracy"], label = "validating")
plt.legend()

model.save("/content/drive/My Drive/mobile.h5")

his = model.fit(train_gen, 
      steps_per_epoch=240,
      epochs=50,
      verbose = 1,
      validation_data = val_gen,
      validation_steps = 10,
      shuffle = True,
)

plt.plot(his.history["accuracy"], label = "training")
plt.plot(his.history["val_accuracy"], label = "validating")
plt.legend()

model.save("/content/drive/My Drive/mobile2.h5")

"""# EfficientNet"""

def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):
    def eraser(input_img):
        if input_img.ndim == 3:
            img_h, img_w, img_c = input_img.shape
        elif input_img.ndim == 2:
            img_h, img_w = input_img.shape

        p_1 = np.random.rand()

        if p_1 > p:
            return input_img

        while True:
            s = np.random.uniform(s_l, s_h) * img_h * img_w
            r = np.random.uniform(r_1, r_2)
            w = int(np.sqrt(s / r))
            h = int(np.sqrt(s * r))
            left = np.random.randint(0, img_w)
            top = np.random.randint(0, img_h)

            if left + w <= img_w and top + h <= img_h:
                break

        if pixel_level:
            if input_img.ndim == 3:
                c = np.random.uniform(v_l, v_h, (h, w, img_c))
            if input_img.ndim == 2:
                c = np.random.uniform(v_l, v_h, (h, w))
        else:
            c = np.random.uniform(v_l, v_h)

        input_img[top:top + h, left:left + w] = c

        return input_img

    return eraser

from tensorflow.keras.applications import EfficientNetB0, efficientnet

custom_preprocess = lambda img: efficientnet.preprocess_input(get_random_eraser()(img))

AUGMENTATIONS = A.Compose([
            A.Rotate(limit=40),
            A.OneOf([
                     A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),
                     A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)
            ]),
            A.OneOf([
                     A.ElasticTransform(alpha=224, sigma=224 * 0.05, alpha_affine=224 * 0.03),
                     A.GridDistortion(),
                     A.OpticalDistortion(distort_limit=2, shift_limit=0.5),
            ], p=0.3),
            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),
            A.RandomContrast(limit=0.2, p=0.5),
            A.HorizontalFlip(),
            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10),
    ])

train_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                            augment = AUGMENTATIONS,
                            preprocess_input = custom_preprocess,
                            validation_split=0.2,
)

val_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                             validation_split=0.2,
                             preprocess_input= efficientnet.preprocess_input
)

test_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                             preprocess_input= efficientnet.preprocess_input
)

train_gen = train_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "training",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

val_gen = val_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "validation",
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)


test_gen = test_datagen.flow_from_dataframe(test,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            shuffle=True,
                            target_size=(224, 224),
                            validate_filenames = True,
)

from tensorflow.keras.layers import (GlobalAveragePooling2D, 
  Dropout, Dense, BatchNormalization)
from tensorflow.keras import optimizers, losses

from tensorflow.keras.applications import EfficientNetB0

def unfreeze_model(model):
    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen
    for layer in model.layers[-20:]:
        if not isinstance(layer, layers.BatchNormalization):
            layer.trainable = True

inputs = tf.keras.Input(shape=(224, 224, 3), name = "image_input")
conv_base = EfficientNetB0(input_shape=(224, 224,3), input_tensor= inputs, drop_connect_rate=0.4,
                       include_top = False)

conv_base.trainable = False

unfreeze_model(conv_base)
# x = conv_base(inputs, training=False, )
# x = conv_base
x=GlobalAveragePooling2D()(conv_base.output)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
x=Dense(512,activation='relu')(x)
x=Dense(256,activation='relu')(x)
x=Dense(128,activation='relu')(x)
preds=Dense(3,activation='softmax')(x)
 
model= tf.keras.Model(inputs=inputs,outputs=[preds], name = "our_model")
model.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=1e-3),
    metrics=['accuracy'])

def train_model(model):
  from datetime import datetime
  import json
  
  save_dir = "/content/drive/My Drive/model/eff2nd"
 
  # Reduce learning rate when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.01,
                                                  patience = 3,
                                                  factor = 0.25,
                                                  verbose = 1,
                                                  cooldown = 0,
                                                  min_lr = 0.00000001)
 
  # Stop the training process when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.005,
                                                  patience = 13,
                                                  verbose = 1,
                                                  restore_best_weights = True)
  

  txt_log = open(save_dir+".log", mode='wt', buffering=1)
  
  log_callback = tf.keras.callbacks.LambdaCallback(
    on_epoch_end = lambda epoch, logs: txt_log.write(
      json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\n'),
    on_train_end = lambda logs: txt_log.close()
  )


  his = model.fit(train_gen, 
      steps_per_epoch=242,
      epochs=60,
      callbacks=[
                 tf.keras.callbacks.ModelCheckpoint(filepath=save_dir + '.{epoch:02d}-{val_accuracy:.2f}.h5'),
                 early_stopper, reduce_lr,
                 log_callback,
                 ],
      verbose = 1,
      # class_weight = class_weights,
      validation_data = val_gen,
      validation_steps = 61,
      shuffle = True,
  )
  plt.plot(his.history["accuracy"], label = "training")
  plt.plot(his.history["val_accuracy"], label = "validating")
  plt.legend()
  plt.savefig(save_dir + "plot.jpg")
 
  cur = datetime.now()
  save_dir += str(cur.day) + "-" + str(cur.hour)
 
  model.save(save_dir)
train_model(model)

test_gen = test_datagen.flow_from_dataframe(test,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            shuffle=False,
                            target_size=(224, 224),
                            validate_filenames = True,
)
test_gen.reset()

y_pred1 = model.predict(test_gen)

def check_acc(y_pred, gen):
  from sklearn.metrics import accuracy_score
  pred_cls = np.argmax(y_pred,axis = 1)
  true_cls = test_gen.classes
  return accuracy_score(true_cls, pred_cls)

check_acc(y_pred1, test_gen)

model = tf.keras.models.load_model("/content/drive/My Drive/model/mobile3rd.19-0.89.h5")

y_pred2 = model.predict(test_gen)

check_acc(y_pred2, test_gen)

"""### edge detection"""

labels_path = '/content/drive/My Drive/M499/tranch2_labels.csv'
labels = pd.read_csv(labels_path)

img = cv2.imread("/content/drive/My Drive/M499/edge/" + labels["final_url"][0])
plt.imshow(img)

labels.info()

labels.isnull().sum()

labels = labels.dropna()
labels.index = range(len(labels))

labels["primary_posture"].value_counts()

labels = labels.query("primary_posture != 'Unknown'")

labels.final_url = labels.final_url.map(lambda s: ".".join([s.rsplit(".",1)[0], "png"]))

from sklearn.model_selection import train_test_split
train, test = train_test_split(labels, test_size=0.15, random_state=42)
len(train), len(test)

def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):
    def eraser(input_img):
        if input_img.ndim == 3:
            img_h, img_w, img_c = input_img.shape
        elif input_img.ndim == 2:
            img_h, img_w = input_img.shape

        p_1 = np.random.rand()

        if p_1 > p:
            return input_img

        while True:
            s = np.random.uniform(s_l, s_h) * img_h * img_w
            r = np.random.uniform(r_1, r_2)
            w = int(np.sqrt(s / r))
            h = int(np.sqrt(s * r))
            left = np.random.randint(0, img_w)
            top = np.random.randint(0, img_h)

            if left + w <= img_w and top + h <= img_h:
                break

        if pixel_level:
            if input_img.ndim == 3:
                c = np.random.uniform(v_l, v_h, (h, w, img_c))
            if input_img.ndim == 2:
                c = np.random.uniform(v_l, v_h, (h, w))
        else:
            c = np.random.uniform(v_l, v_h)

        input_img[top:top + h, left:left + w] = c

        return input_img

    return eraser

from tensorflow.keras.applications import EfficientNetB0, efficientnet

train_preprocess = lambda img: efficientnet.preprocess_input(get_random_eraser()(img))

AUGMENTATIONS = A.Compose([
            A.Rotate(limit=40),
            A.OneOf([
                     A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),
                     A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)
            ]),
            A.OneOf([
                     A.ElasticTransform(alpha=224, sigma=224 * 0.05, alpha_affine=224 * 0.03),
                     A.GridDistortion(),
                     A.OpticalDistortion(distort_limit=2, shift_limit=0.5),
            ], p=0.3),
            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),
            A.RandomContrast(limit=0.2, p=0.5),
            A.HorizontalFlip(),
            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10),
    ])

train_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                            augment = AUGMENTATIONS,
                            preprocess_input = train_preprocess,
                            validation_split=0.2,
)

val_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                             validation_split=0.2,
                             preprocess_input= efficientnet.preprocess_input
)

test_datagen = ImageDataAugmentor(data_format="channels_last",
                            #  rescale = 1./255,
                             preprocess_input= efficientnet.preprocess_input
)

train_gen = train_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/edge",
                            x_col = "final_url",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "training",
                            shuffle=True,
                            target_size=(224, 224),
                            # validate_filenames = True,
)

val_gen = val_datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/edge",
                            x_col = "final_url",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "validation",
                            shuffle=True,
                            target_size=(224, 224),
                            # validate_filenames = True,
)


test_gen = test_datagen.flow_from_dataframe(test,
                            directory = "/content/drive/My Drive/M499/edge",
                            x_col = "final_url",
                            y_col = "primary_posture",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            shuffle=True,
                            target_size=(224, 224),
                            # validate_filenames = True,
)

from tensorflow.keras.layers import (GlobalAveragePooling2D, 
  Dropout, Dense, BatchNormalization)
from tensorflow.keras import optimizers, losses

from tensorflow.keras.applications import EfficientNetB0

def unfreeze_model(model):
    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen
    for layer in model.layers[-20:]:
        if not isinstance(layer, layers.BatchNormalization):
            layer.trainable = True

inputs = tf.keras.Input(shape=(224, 224, 3), name = "image_input")
conv_base = EfficientNetB0(input_shape=(224, 224,3), input_tensor= inputs, drop_connect_rate=0.4,
                       include_top = False)

conv_base.trainable = False

unfreeze_model(conv_base)
# x = conv_base(inputs, training=False, )
# x = conv_base
x=GlobalAveragePooling2D()(conv_base.output)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
x = Dense(1024, activation = 'relu')(x)
x=Dense(512,activation='relu')(x)
x=Dense(256,activation='relu')(x)
x=Dense(128,activation='relu')(x)
preds=Dense(3,activation='softmax')(x)
 
model= tf.keras.Model(inputs=inputs,outputs=[preds], name = "our_model")
model.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=1e-3),
    metrics=['accuracy'])

def train_model(model):
  from datetime import datetime
  import json
  
  save_dir = "/content/drive/My Drive/model/edge"
 
  # Reduce learning rate when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.01,
                                                  patience = 3,
                                                  factor = 0.25,
                                                  verbose = 1,
                                                  cooldown = 0,
                                                  min_lr = 0.00000001)
 
  # Stop the training process when there is a change lesser than <min_delta> in <val_accuracy> for more than <patience> epochs
  early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',
                                                  mode = 'max',
                                                  min_delta = 0.005,
                                                  patience = 13,
                                                  verbose = 1,
                                                  restore_best_weights = True)
  

  txt_log = open(save_dir+".log", mode='wt', buffering=1)
  
  log_callback = tf.keras.callbacks.LambdaCallback(
    on_epoch_end = lambda epoch, logs: txt_log.write(
      json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\n'),
    on_train_end = lambda logs: txt_log.close()
  )


  his = model.fit(train_gen, 
      steps_per_epoch=202,
      epochs=60,
      callbacks=[
                 tf.keras.callbacks.ModelCheckpoint(filepath=save_dir + '.{epoch:02d}-{val_accuracy:.2f}.h5'),
                 early_stopper, reduce_lr,
                 log_callback,
                 ],
      verbose = 1,
      # class_weight = class_weights,
      validation_data = val_gen,
      validation_steps = 51,
      shuffle = True,
  )
  plt.plot(his.history["accuracy"], label = "training")
  plt.plot(his.history["val_accuracy"], label = "validating")
  plt.legend()
  plt.savefig(save_dir + "plot.jpg")
 
  cur = datetime.now()
  save_dir += str(cur.day) + "-" + str(cur.hour)
 
  model.save(save_dir)
train_model(model)



"""# pytorch pipeline"""

class RangeTransformer():
  def __call__(self,img):
    if img.dtype == np.float32:
      ## map [0, 1] -> [0, 255]
      img *= 255
      img = img.astype(np.uint8)
    return img

transformations = transforms.Compose([
    RangeTransformer(),
    transforms.ToPILImage(),
    transforms.RandomResizedCrop(200),
    transforms.ToTensor(),
    # transforms.Normalize(mean=[0.485, 0.456, 0.406],
    #                      std=[0.229, 0.224, 0.225]),
    
])

# assume label is "how-many"
class ImageData(torch.utils.data.Dataset):
  def __init__(self, df, zip, transform = None):
    self.df = df
    self.zip = zip
    self.transform = transform
  def __len__(self):
    return len(self.df)
  def __getitem__(self, idx):
    img = self.zip.open(self.df.loc[idx].file_path)
    img = plt.imread(img)
    if self.transform:
      img = self.transform(img)
    return (img, df.loc[idx]["how_many"])
  def getIndex(self):
    return self.df.index

ID = ImageData(train, zip_file,
               transform=transformations
               )
testID = ImageData(train, zip_file,
               transform=transformations
               )

def plotIDImage(img):
  img = img.permute(1,2,0)
  plt.imshow(img)


def ViewImageDate(num = 6):
  randoms = np.random.choice(train.index, num, replace=False)
  fig = plt.figure(figsize=(8, 20))

  for i in range(num):
    plt.subplot(num, 2, i + 1)
    random = randoms[i]
    img, label = ID[random]

    plotIDImage(img)
    plt.title(f"#{random} label = {label}")
  plt.tight_layout()
  
ViewImageDate()

ImageLoader = torch.utils.data.DataLoader(ID, batch_size = 16, 
                                          sampler = torch.utils.data.SubsetRandomSampler(ID.getIndex())
                                          )
# TestLoader = torch.utils.data.DataLoader(testID, batch_size = 16)
for i in ImageLoader:
  X, y = i
  print(X.shape, y.shape)
  break

im_num = np.random.randint(0,len(df))
im = plt.imread(zip_file.open(df.iloc[im_num].file_path))
print(df.iloc[im_num, 2:])
plt.imshow(im)

"""# Rest"""

his = model.fit(train_gen, 
      steps_per_epoch=240,
      epochs=30,
      verbose = 1,
      validation_data = val_gen,
      validation_steps = 10,
      shuffle = True,
)

plt.plot(his.history["accuracy"], label = "training")
plt.plot(his.history["val_accuracy"], label = "validating")
plt.legend()

from tensorflow.keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(data_format="channels_last",
                             rescale = 1./255,
                             validation_split=0.1,
)
train_gen = datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "how_many",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "training",
                            shuffle=True,
                            target_size=(100, 100),
                            validate_filenames = False,
)
val_gen = datagen.flow_from_dataframe(train,
                            directory = "/content/drive/My Drive/M499/data",
                            x_col = "file_path",
                            y_col = "how_many",
                            class_mode="sparse",
                            batch_size = 32,
                            seed=42,
                            subset = "validation",
                            shuffle=True,
                            target_size=(100, 100),
                            validate_filenames = False,
)
for i in train_gen:
  img, label = i
  print(label.shape)
  plt.imshow((img[0,...]*255).astype(np.uint8))
  break

from keras import layers
from keras import models
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100,100, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(4, activation='softmax'))
model.summary()

from tensorflow.keras import optimizers, losses
model.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=1e-3),
    metrics=['accuracy'])

his = model.fit(train_gen, 
      steps_per_epoch=20,
      epochs=10,
      verbose = 1,
      validation_data = val_gen,
      validation_steps = 10,
      shuffle = True,
)

plt.plot(his.history["accuracy"], label = "training")
plt.plot(his.history["val_accuracy"], label = "validating")
plt.legend()

from keras import layers
from keras import models
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100,100, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(4, activation='softmax'))
model.summary()

from tensorflow.keras import optimizers, losses
model.compile(loss=losses.SparseCategoricalCrossentropy(from_logits=False),
    optimizer=optimizers.Adam(learning_rate=1e-4, ),
    metrics=['accuracy'])

his = model.fit(train_gen, 
      steps_per_epoch=20,
      epochs=10,
      verbose = 1,
      validation_data = val_gen,
      validation_steps = 10,
      shuffle = True,
)

plt.plot(his.history["accuracy"], label = "training")
plt.plot(his.history["val_accuracy"], label = "validating")
plt.legend()